{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "rxnorm_input_path=\"C:\\\\Users\\\\visha\\\\Documents\\\\novartis\\\\implementation_withoutapi\\\\data\\\\rxnorm\"\n",
    "fda_input_path=\"C:\\\\Users\\\\visha\\\\Documents\\\\novartis\\\\implementation_withoutapi\\\\data\\\\fda\"\n",
    "triples_output_path=\"C:\\\\Users\\\\visha\\\\Documents\\\\novartis\\\\implementation_withoutapi\\\\results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function: Write results to tsv file\n",
    "def write_tsv(file_name, data_lists):\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"node1\\tlabel\\tnode2\\n\")\n",
    "        for data in data_lists:\n",
    "            line = \"\\t\".join(data)\n",
    "            line += \"\\n\"\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare list to hold all triples\n",
    "triples_all=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header= ['RXCUI', 'LAT', 'TS', 'LUI', 'STT', 'SUI', 'ISPREF', 'RXAUI', 'SAUI', 'SCUI', 'SDUI', 'SAB', 'TTY', 'CODE', 'STR', 'SRL', 'SUPPRESS', 'CVF']\n"
     ]
    }
   ],
   "source": [
    "#Create a dictionary to hold all the Term types for an RXNorm\n",
    "rxcui_tty_dict={}\n",
    "\n",
    "#RXNCONSO table: gives rxcui, name(label),tty(description), synonym(alias), language(ENG) and suppress(Y/N)\n",
    "#RXNCONSO table: gives related identifiers e.g. MSH, DRUGBANK, SNOMEDCT\n",
    "filename= os.path.join(rxnorm_input_path, 'rxnconso.csv')\n",
    "\n",
    "with open(filename, encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    \n",
    "    #Get the list of headers from the file\n",
    "    header_list = next(reader)\n",
    "    print(\"Header=\", header_list)\n",
    "    \n",
    "    \n",
    "    for row in reader:\n",
    "        triples=[]\n",
    "        \n",
    "        #Check the identifier is not RXNORM i.e MSH, SNOMED, DRUGBANK etc.\n",
    "        #since RXNORM is the subject and we already get the rxcui from the name\n",
    "        if row[11] != 'RXNORM':\n",
    "            #print(\"Subject Identifier=\",row[0])\n",
    "            #print(row[0], row[11], row[13])\n",
    "            \n",
    "            #Get the triples related to identifiers- MSH, SNOMED etc.\n",
    "            triples.append(\"\\\"\"+row[0]+\"\\\"\")\n",
    "            triples.append(row[11])\n",
    "            triples.append(\"\\\"\"+row[13]+\"\\\"\")\n",
    "            \n",
    "            #Append triples related to identifiers to list of all triples\n",
    "            triples_all.append(triples)\n",
    "                \n",
    "        \n",
    "        #Declare list of triples for lang, rxcui, tty, name, synonym, suppress\n",
    "        triples_lang=[]\n",
    "        triples_rxcui=[]\n",
    "        triples_tty=[]\n",
    "        triples_name=[]\n",
    "        triples_suppress=[]\n",
    "        triples_synonym=[]\n",
    "        \n",
    "        #Check identifier is RXNORM and is not a Synonym/Tall Man Lettering Synonym/Prescribable Name\n",
    "        #This gives us all the required RXNORM triples other than synonym\n",
    "        if row[11] == 'RXNORM' and row[12] not in ('SY', 'TMSY', 'PSN'):\n",
    "            #print(\"Subject Triples=\",row[0])\n",
    "            \n",
    "            #Get the triples for language\n",
    "            triples_lang.append(\"\\\"\"+row[0]+\"\\\"\")\n",
    "            triples_lang.append(\"language\")\n",
    "            triples_lang.append(\"\\\"\"+row[1]+\"\\\"\")\n",
    "            \n",
    "            #Get the triples for rxcui\n",
    "            triples_rxcui.append(\"\\\"\"+row[0]+\"\\\"\")\n",
    "            triples_rxcui.append(\"rxcui\")\n",
    "            triples_rxcui.append(\"\\\"\"+row[13]+\"\\\"\")\n",
    "            \n",
    "            #Get the triples for tty (description)\n",
    "            triples_tty.append(\"\\\"\"+row[0]+\"\\\"\")\n",
    "            triples_tty.append(\"tty\")\n",
    "            triples_tty.append(\"\\\"\"+row[12]+\"\\\"\")\n",
    "            \n",
    "            #Add the tty in the dictionary for the subject\n",
    "            rxcui_tty_dict[row[0]]=row[12]\n",
    "            \n",
    "            #Get the triples for name (label)\n",
    "            triples_name.append(\"\\\"\"+row[0]+\"\\\"\")\n",
    "            triples_name.append(\"name\")\n",
    "            triples_name.append(\"\\\"\"+row[14]+\"\\\"\")\n",
    "            \n",
    "            #Get the triples for suppress\n",
    "            triples_suppress.append(\"\\\"\"+row[0]+\"\\\"\")\n",
    "            triples_suppress.append(\"suppress\")\n",
    "            triples_suppress.append(\"\\\"\"+row[16]+\"\\\"\")\n",
    "            \n",
    "            #Append triples for lang, rxcui, tty, name, synonym, suppress\n",
    "            if triples_lang != []:\n",
    "                triples_all.append(triples_lang)\n",
    "            if triples_rxcui != []:\n",
    "                triples_all.append(triples_rxcui)\n",
    "            if triples_tty != []:\n",
    "                triples_all.append(triples_tty)\n",
    "            if triples_name != []:\n",
    "                triples_all.append(triples_name)\n",
    "            if triples_suppress !=[]:\n",
    "                triples_all.append(triples_suppress)\n",
    "        \n",
    "        #Check identifier is RXNORM and is a Synonym/Tall Man Lettering Synonym/Prescribable Name\n",
    "        #This gives us all the required triples for synonym\n",
    "        if row[11] == 'RXNORM' and row[12] in ('SY', 'TMSY', 'PSN'):\n",
    "            #print(\"Subject Triples=\",row[0])\n",
    "            \n",
    "            #Get all triples for synonym\n",
    "            triples_synonym.append(\"\\\"\"+row[0]+\"\\\"\")\n",
    "            triples_synonym.append(\"synonym\")\n",
    "            triples_synonym.append(\"\\\"\"+row[14]+\"\\\"\")\n",
    "            \n",
    "            #Append triples for synonym\n",
    "            if triples_synonym !=[]:\n",
    "                triples_all.append(triples_synonym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the required triples for RXNorm information and Identifiers to rxnorm_triples.tsv file\n",
    "filename_output= os.path.join(triples_output_path, 'rxnorm_triples.tsv')\n",
    "write_tsv(filename_output, triples_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header= ['RXCUI1', 'RXAUI1', 'STYPE1', 'REL', 'RXCUI2', 'RXAUI2', 'STYPE2', 'RELA', 'RUI', 'SRUI', 'SAB', 'SL', 'RG', 'DIR', 'SUPPRESS', 'CVF']\n"
     ]
    }
   ],
   "source": [
    "#Create a dictionary to hold all relations for a subject\n",
    "rxcui_rel_dict={}\n",
    "\n",
    "#RXNREL table: Gives us all the related RXNORMs for an RXNORMID\n",
    "filename= os.path.join(rxnorm_input_path, 'rxnrel.csv')\n",
    "\n",
    "with open(filename, encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    \n",
    "    #Get the list of headers from the file\n",
    "    header_list = next(reader)\n",
    "    print(\"Header=\", header_list)\n",
    "    \n",
    "    \n",
    "    for row in reader:\n",
    "        triples=[]\n",
    "        \n",
    "        #We only need the relations between the concepts (CUI) and not atoms (AUI)\n",
    "        if row[2]=='AUI':\n",
    "            break\n",
    "            \n",
    "        #For the subject we need to split the RXNORM which is present in this form '1656341.0'\n",
    "        x=row[4].split(\".\",1)[0]\n",
    "    \n",
    "        #We only need the relation between the concepts\n",
    "        if row[2]=='CUI' and row[6]=='CUI':\n",
    "            subject=x\n",
    "            #print(\"Subject Rel=\",x)\n",
    "            # print(row[4], row[7], row[0])\n",
    "            \n",
    "            #Get the triples for RXNORM Relations\n",
    "            triples.append(\"\\\"\"+subject+\"\\\"\")\n",
    "            triples.append(row[7])\n",
    "            #Split the object since object is also of the form '1656341.0'\n",
    "            obj=row[0].split(\".\",1)[0]\n",
    "            triples.append(\"\\\"\"+obj+\"\\\"\")\n",
    "            \n",
    "            #Check if the subject is in the Relation dictionary=> Then Add the relation for the subject\n",
    "            if subject not in rxcui_rel_dict:\n",
    "                rxcui_rel_dict[subject]=[]\n",
    "                rxcui_rel_dict[subject].append([row[7],obj])\n",
    "            else:\n",
    "                rxcui_rel_dict[subject].append([row[7],obj])\n",
    "                \n",
    "                \n",
    "            #Append the triples for RXNORM relations to the list of all triples\n",
    "            triples_all.append(triples)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the required triples for RXNorm Relations to rxnorm_triples.tsv file\n",
    "filename_output= os.path.join(triples_output_path, 'rxnorm_triples.tsv')\n",
    "write_tsv(filename_output, triples_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Tty dict:\",rxcui_tty_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Tty rel:\",rxcui_rel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RXNSAT: Gives us information about the Source Atoms such as NDC Codes and UMLSCUI:\n",
    "filename= os.path.join(rxnorm_input_path, 'rxnsat.csv')\n",
    "with open(filename, encoding=\"utf-8\") as f:\n",
    "\n",
    "    reader = csv.reader(f)\n",
    "    \n",
    "    #Get the list of headers from the file\n",
    "    header_list = next(reader)\n",
    "    #print(\"Header=\", header_list)\n",
    "    \n",
    "    \n",
    "    for row in reader:\n",
    "        triples=[]\n",
    "          \n",
    "        #Check if the identifier source is RXNORM and the related fields are NDC or UMLSCUI\n",
    "        if row[9]== 'RXNORM' and row[8] in ('NDC', 'UMLSCUI'):\n",
    "            #print(\"Subject SAT=\",row[0])\n",
    "            \n",
    "            #Get the triples for NDC and UMLSCUI\n",
    "            triples.append(\"\\\"\"+row[0]+\"\\\"\")\n",
    "            triples.append(row[8])\n",
    "            triples.append(\"\\\"\"+row[10]+\"\\\"\")\n",
    "            \n",
    "            #Append triples for NDC and UMLSCUI to the list of all triples\n",
    "            triples_all.append(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the required triples for RXNorm Source Identifiers- NDC, UMLSCUI to rxnorm_triples.tsv file\n",
    "filename_output= os.path.join(triples_output_path, 'rxnorm_triples.tsv')\n",
    "write_tsv(filename_output, triples_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list to hold all known identifiers\n",
    "identifier_source_list=[\n",
    "\"USP\"\n",
    ",\"GS\"\n",
    ",\"SNOMEDCT_US\"\n",
    ",\"VANDF\"\n",
    ",\"MTHSPL\"\n",
    ",\"NDDF\"\n",
    ",\"ATC\"\n",
    ",\"MMSL\"\n",
    ",\"MSH\"\n",
    ",\"DRUGBANK\"\n",
    ",\"MMX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list to hold all known relationship types\n",
    "rela_types_list=[\n",
    "'consists_of',\n",
    "'constitutes',\n",
    "'contained_in',\n",
    "'contains',\n",
    "'dose_form_of',\n",
    "'form_of',\n",
    "'has_dose_form',\n",
    "'doseformgroup_of',\n",
    "'has_form',\n",
    "'has_ingredient',\n",
    "'has_ingredients',\n",
    "'has_part',\n",
    "'has_precise_ingredient',\n",
    "'has_quantified_form',\n",
    "'has_tradename',\n",
    "'has_doseformgroup',\n",
    "'ingredient_of',\n",
    "'ingredients_of',\n",
    "'inverse_isa',\n",
    "'isa',\n",
    "'part_of',\n",
    "'precise_ingredient_of',\n",
    "'quantified_form_of',\n",
    "'reformulated_to',\n",
    "'reformulation_of',\n",
    "'tradename_of'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary to hold all Term Types and their meanings \n",
    "tty_dict={\n",
    "   'BN': 'brand_name' \n",
    "  ,'BPCK': 'branded_pack'    \n",
    "  ,'DF': 'dose_form'   \n",
    "  ,'DFG': 'dose_form_group'\n",
    "  ,'ET': 'dose_form_entry_term'    \n",
    "  ,'GPCK': 'generic_pack'    \n",
    "  ,'IN': 'ingredient'   \n",
    "  ,'MIN': 'multiple_ingredients'   \n",
    "  ,'PIN': 'precise_ingredient'    \n",
    "  ,'SBD': 'branded_drug'\n",
    "  ,'SBDC': 'branded_drug_component'\n",
    "  ,'SBDF': 'branded_dose_form'\n",
    "  ,'SBDG': 'branded_dose_form_group'\n",
    "  ,'SCD': 'clinical_drug'\n",
    "  ,'SCDC': 'clinical_drug_component'\n",
    "  ,'SCDF': 'clinical_dose_form'\n",
    "  ,'SCDG': 'clinical_dose_form_group'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary to hold all predicates and their corresponding Wikidata PNodes\n",
    "pred_wikidata_dict={\n",
    "        'instanceOf':'P31'\n",
    "        ,'rxcui':'P3345'\n",
    "        ,'UMLSCUI':'P2892'\n",
    "        ,'SNOMEDCT_US':'P5806'\n",
    "        ,'MSH':'P486'\n",
    "        ,'DRUGBANK':'P715'\n",
    "        ,'NDC': 'P3640'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary to hold the predicates not in Wikidata\n",
    "pred_notinwikidata_dict={}\n",
    "\n",
    "#Create a list to hold output of triples of QRXNodes with predicates in Wikidata\n",
    "output_rows_pred_wiki=[]\n",
    "\n",
    "#Create a list to hold output of triples of QRXNodes with predicates NOT in Wikidata\n",
    "output_rows_pred_notwiki=[]\n",
    "\n",
    "#Create a list to hold output of triples of PRXNOdes\n",
    "output_rows_prxnode=[]\n",
    "\n",
    "#Create a list to hold output of triples of PRXNode- Edges and DataTypes\n",
    "output_rows_prxnode_edges=[]\n",
    "output_rows_prxnode_datatype=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function: Generate a SPARQL query given an identifier\n",
    "def get_query(identifier):\n",
    "    query = \"\"\"#All items with a property\n",
    "    # Sample to query all values of a property\n",
    "    # Property talk pages on Wikidata include basic queries adapted to each property\n",
    "    SELECT\n",
    "      ?item ?itemLabel\n",
    "      ?value ?valueLabel\n",
    "    # valueLabel is only useful for properties with item-datatype\n",
    "    WHERE \n",
    "    {\n",
    "      ?item wdt:\"\"\"+pred_wikidata_dict[identifier]+\"\"\" ?value\n",
    "              \n",
    "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "    }\n",
    "    # remove or change limit for more results\n",
    "    \"\"\"\n",
    "    return query\n",
    "\n",
    "#Function: Get the results from Wikidata SPARQL endpoint given a query\n",
    "def get_results(endpoint_url, query):\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dict to hold all QNodes in Wikidata which have RXNORMIDs\n",
    "qnode_dict_inwiki={}\n",
    "\n",
    "#Specify the endpoint for the url and the identifier name\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "identifier=\"rxcui\"\n",
    "\n",
    "#Generate the query\n",
    "query=get_query(identifier)\n",
    "#print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the results from the Query\n",
    "results = get_results(endpoint_url, query)\n",
    "   \n",
    "#From the results, get the RXNorm IDs as the Key and QNodes as the Value   \n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    \n",
    "    if result['item']['type']=='uri':\n",
    "        qnode=result['item']['value']\n",
    "        identifier_value=result['value']['value']\n",
    "        qnode=qnode.split(\"entity/\",1)[1]\n",
    "        if identifier=='rxcui':\n",
    "            qnode_dict_inwiki[identifier_value]=qnode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"IN Wiki=\",qnode_dict_inwiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list to hold triples for RXNorm Qnodes\n",
    "triples_qnode_all=[]\n",
    "\n",
    "#Create triples for subject QNode, Predicate- P3345 and value as the RXNormID\n",
    "for x in qnode_dict_inwiki:\n",
    "    triples_qnode=[]\n",
    "    triples_qnode.append(qnode_dict_inwiki[x])\n",
    "    triples_qnode.append('P3345')\n",
    "    triples_qnode.append(\"\\\"\"+x+\"\\\"\")\n",
    "    \n",
    "    #Append the result to the list of all Qnode triples\n",
    "    triples_qnode_all.append(triples_qnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the list of triples for RXNorm QNodes to Qnode_Predicates_Wiki file\n",
    "filename_output= os.path.join(triples_output_path, 'qnode_pred_wiki.tsv')\n",
    "write_tsv(filename_output, triples_qnode_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header= ['node1', 'label', 'node2']\n"
     ]
    }
   ],
   "source": [
    "#Load the rxnorm_triples file which contains all RXNorm Information, Identifiers, Relations and Source Identifiers\n",
    "rxnorm_triples_file= os.path.join(triples_output_path, 'rxnorm_triples.tsv')\n",
    "\n",
    "with open(rxnorm_triples_file, encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    \n",
    "    #Get the list of all headers in the file\n",
    "    header_list = next(reader)\n",
    "    print(\"Header=\", header_list)\n",
    "    \n",
    "    #Create a dictionary to hold QRXNodes for the RXNormIDs\n",
    "    qnode_dict_notinwiki={}\n",
    "    \n",
    "    #Create label and description as '' (Not needed since we are using QRXNode method)\n",
    "    label=''\n",
    "    desc=''\n",
    "    \n",
    "    #Read every row from the rxnorm_triples file\n",
    "    for row in reader:\n",
    "        output_row=[]\n",
    "        \n",
    "       \n",
    "        #output_row.append(str(row[0]))\n",
    "        \n",
    "        #Get the label and description \n",
    "        #Alt-Method: label+description can also work- Not used here\n",
    "        if row[1]=='name':\n",
    "            label=str(row[2])\n",
    "            \n",
    "        if row[1]=='tty':\n",
    "            desc=str(tty_dict[row[2]].replace(\"_\",\" \"))\n",
    "        \n",
    "        #If subject is not in the dictionary and not in Wikidata, then add the QRXNode in the value\n",
    "        if row[0] not in qnode_dict_notinwiki and row[0] not in qnode_dict_inwiki:\n",
    "            qnode_dict_notinwiki[row[0]]='QRX'+str(row[0])\n",
    "            \n",
    "            #Alt-Method: label+description can also work- Not used here\n",
    "            #label_desc_dict[row[0]]=label+'-'+desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(qnode_dict_notinwiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the QRXNodes in qnode_dict_notinwiki and add P31 predicate for all\n",
    "#The object is Pharmaceutical Product/ Q28885102 for all\n",
    "for x in qnode_dict_notinwiki.keys():\n",
    "   \n",
    "    #print(x)\n",
    "    output_row=[]  \n",
    "   \n",
    "    #Get all triples for P31\n",
    "    output_row.append(qnode_dict_notinwiki[x])\n",
    "    output_row.append(pred_wikidata_dict['instanceOf'])    \n",
    "    output_row.append(\"Q28885102\")\n",
    "    #print(output_row)\n",
    "    \n",
    "    #Append triples to the Output of Predicates in Wikidata\n",
    "    output_rows_pred_wiki.append(output_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the output to QRXNode Predicates in Wikidata file\n",
    "filename_output= os.path.join(triples_output_path, 'qrxnode_pred_wiki.tsv')\n",
    "write_tsv(filename_output, output_rows_pred_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header= ['node1', 'label', 'node2']\n"
     ]
    }
   ],
   "source": [
    "#Load the rxnorm_triples file which contains all RXNorm Information, Identifiers, Relations and Source Identifiers\n",
    "rxnorm_triples_file= os.path.join(triples_output_path, 'rxnorm_triples.tsv')\n",
    "\n",
    "with open(rxnorm_triples_file, encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    \n",
    "    #Get all the headers from the file\n",
    "    header_list = next(reader)\n",
    "    print(\"Header=\", header_list)\n",
    "    \n",
    "    #Check every row for QRXNode triples\n",
    "    for row in reader:\n",
    "        output_row=[]\n",
    "    \n",
    "        #Get the object\n",
    "        obj=str(row[2])\n",
    "        \n",
    "        #Get the predicate\n",
    "        pred=str(row[1])\n",
    "        \n",
    "        #If predicate is name, change it to label\n",
    "        if pred==\"name\":\n",
    "            pred=\"label\"\n",
    "        #If predicate is tty, change it to description, remove the underscore(_) from the object\n",
    "        elif pred==\"tty\":\n",
    "            pred=\"description\"\n",
    "            obj=tty_dict[obj].replace(\"_\",\" \")\n",
    "        #If predicate is synonym, change it to alias\n",
    "        elif pred==\"synonym\":\n",
    "            pred=\"alias\"\n",
    "        #If predicate is present in Term Type dictionary, change it to meaniningful context using the dictionary\n",
    "        elif pred in tty_dict.keys():\n",
    "            pred=tty_dict[pred]\n",
    "            \n",
    "            #Check if object has QRXNode then make object as QRXNode\n",
    "            if obj in qnode_dict_notinwiki.keys():\n",
    "                obj=qnode_dict_notinwiki[obj]\n",
    "            #Check if object has QNode then make object as QNode\n",
    "            elif obj in qnode_dict_inwiki.keys():\n",
    "                obj=qnode_dict_inwiki[obj]\n",
    "            #Else just a check but this is not possible\n",
    "            else:\n",
    "                print(\"Not in Both!\")\n",
    "        #If predicate is present in RXNorm Relations list\n",
    "        elif pred in rela_types_list:\n",
    "            #Check if object has QRXNode then make object as QRXNode\n",
    "            if obj in qnode_dict_notinwiki.keys():\n",
    "                obj=qnode_dict_notinwiki[obj]\n",
    "            #Check if object has QNode then make object as QNode\n",
    "            elif obj in qnode_dict_inwiki.keys():\n",
    "                obj=qnode_dict_inwiki[obj]\n",
    "            #Else just a check but this is not possible\n",
    "            else:\n",
    "                obj=\"QRX\"+obj #temp\n",
    "                \n",
    "           \n",
    "        \n",
    "        \n",
    "        #If predicate is label, description, alias or suppress, use escape sequence for Quotes inside (')\n",
    "        if pred in (\"alias\", \"label\", \"description\", \"suppress\"):\n",
    "            if \"'\" in obj:\n",
    "                obj=obj.replace(\"\\'\",\"\")\n",
    "            \n",
    "            #Change the object to have Quotes followed by @ and then the language en as default since all are english\n",
    "            if obj != '':\n",
    "                obj=\"\\'\"+obj+\"\\'\"+\"@en\"   \n",
    "                \n",
    "        #If predicate is RXCUI or UMLSCUI or in any of the identifiers then change the object to have quotes\n",
    "        if pred in ( \"rxcui\", \"UMLSCUI\") or pred in identifier_source_list or pred == 'NDC':\n",
    "            obj=\"\\\"\"+obj+\"\\\"\"\n",
    "            \n",
    "        #If predicate is language, change the object to en as default since all are english\n",
    "        elif pred ==\"language\":\n",
    "            obj=\"en\"\n",
    "        \n",
    "        \n",
    "        #Check if predicate is an RXNorm information such as label, alias, description \n",
    "        #Check if predicate is an identifier- SNOMED, MSH, DRUGBANK, NDC which has Wikidata PNodes\n",
    "        #Check if object is not empty\n",
    "        if pred in (\"alias\",\"label\",\"description\", \"rxcui\", \"UMLSCUI\", \"SNOMEDCT_US\", \"MSH\", \"DRUGBANK\", \"NDC\") and str(obj) != '':\n",
    "            #Check if the predicate is an identifier, then change the predicate to the corresponding PNodes\n",
    "            if pred in (\"rxcui\", \"UMLSCUI\",\"SNOMEDCT_US\", \"MSH\", \"DRUGBANK\", \"NDC\"):\n",
    "                pred=pred_wikidata_dict[pred]\n",
    "                \n",
    "            #If the subject is Not In Wikidata (has a QRXNode), then append the triples for that QRXNode\n",
    "            if row[0] in qnode_dict_notinwiki:\n",
    "                output_row.append(str(qnode_dict_notinwiki[row[0]]))\n",
    "                output_row.append(str(pred))\n",
    "                output_row.append(str(obj))\n",
    "                \n",
    "                #Append the triples to the QRXNode Predicates in Wikidata file\n",
    "                output_rows_pred_wiki.append(output_row)\n",
    "        else:\n",
    "            #Check if the predicate is not language and object is not empty\n",
    "            if pred not in(\"language\") and str(obj) != '':\n",
    "                #Add key, values pair to the predicates NOT in Wikidata dictionary\n",
    "                \n",
    "                #Check if predicate is in Term Type Dictionary Values, then append PRX_TTY_\n",
    "                if pred in tty_dict.values():\n",
    "                    pred_notinwikidata_dict[pred]=\"PRX_TTY_\"+pred\n",
    "                #Check if predicate is in Identifier Values, then append PRX_ID_\n",
    "                elif pred in identifier_source_list:\n",
    "                    pred_notinwikidata_dict[pred]=\"PRX_ID_\"+pred\n",
    "                #Check if predicate is in RXnorm Relations Values, then append PRX_REL_\n",
    "                elif pred in rela_types_list:\n",
    "                    pred_notinwikidata_dict[pred]=\"PRX_REL_\"+pred\n",
    "                #Else just append PRX_ to denote it is not in Wikidata\n",
    "                else:\n",
    "                     pred_notinwikidata_dict[pred]=\"PRX_\"+pred\n",
    "                pred=pred_notinwikidata_dict[pred]\n",
    "                \n",
    "                #If the subject is Not In Wikidata (has a QRXNode), then append the triples for that QRXNode\n",
    "                if row[0] in qnode_dict_notinwiki:\n",
    "                    \n",
    "                    output_row.append(str(qnode_dict_notinwiki[row[0]]))\n",
    "                    \n",
    "                    output_row.append(str(pred))\n",
    "                    output_row.append(str(obj))\n",
    "                    \n",
    "                    #Append the triples to the QRXNode Predicates NOT in Wikidata file\n",
    "                    output_rows_pred_notwiki.append(output_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the results to the QRXNode Predicate in Wikidata file\n",
    "filename_output= os.path.join(triples_output_path, 'qrxnode_pred_wiki.tsv')\n",
    "write_tsv(filename_output, output_rows_pred_wiki)\n",
    "#Write the results to the QRXNode Predicate NOT in Wikidata file\n",
    "filename_output= os.path.join(triples_output_path, 'qrxnode_pred_notwiki.tsv')\n",
    "write_tsv(filename_output, output_rows_pred_notwiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMSL\n",
      "suppress\n",
      "USP\n",
      "GS\n",
      "VANDF\n",
      "MTHSPL\n",
      "NDDF\n",
      "ATC\n",
      "CVX\n",
      "MMX\n",
      "MTHCMSFRF\n",
      "has_precise_ingredient\n",
      "has_form\n",
      "has_part\n",
      "has_ingredients\n",
      "part_of\n",
      "precise_ingredient_of\n",
      "has_ingredient\n",
      "has_tradename\n",
      "reformulated_to\n",
      "reformulation_of\n",
      "has_dose_form\n",
      "inverse_isa\n",
      "tradename_of\n",
      "form_of\n",
      "dose_form_of\n",
      "contained_in\n",
      "ingredient_of\n",
      "consists_of\n",
      "isa\n",
      "constitutes\n",
      "quantified_form_of\n",
      "contains\n",
      "has_quantified_form\n",
      "ingredients_of\n",
      "has_doseformgroup\n",
      "doseformgroup_of\n"
     ]
    }
   ],
   "source": [
    "#Get all the keys from the Predicate NOT in Wikidata Dictionary\n",
    "for x in pred_notinwikidata_dict.keys():\n",
    "    \n",
    "    print(x)\n",
    "    \n",
    "    output_row=[]\n",
    "    pred_value=pred_notinwikidata_dict[x]\n",
    "    \n",
    "    #Get the triple for label\n",
    "    output_row.append(pred_value)\n",
    "    output_row.append(\"label\")\n",
    "    output_row.append(\"\\'\"+x+\"\\'\"+\"@en\")\n",
    "    \n",
    "    #Append the label triple to both PRXNode file and PRXNode Edges file\n",
    "    output_rows_prxnode.append(output_row)\n",
    "    output_rows_prxnode_edges.append(output_row)\n",
    "    \n",
    "    output_row=[]\n",
    "    #Get the triple for description- For now desciption and label are same\n",
    "    output_row.append(pred_value)\n",
    "    output_row.append(\"description\")\n",
    "    output_row.append(\"\\'\"+x+\"\\'\"+\"@en\")\n",
    "    \n",
    "    #Append the description triple to both PRXNode file and PRXNode Edges file\n",
    "    output_rows_prxnode.append(output_row)\n",
    "    output_rows_prxnode_edges.append(output_row)\n",
    "    \n",
    "    output_row=[]\n",
    "    #Get the triple for Data Type\n",
    "    output_row.append(pred_value)\n",
    "    output_row.append(\"data_type\")\n",
    "    \n",
    "    #Check if predicate is Relation or Term Type, then data type is an item\n",
    "    if (\"PRX_REL_\" in pred_value or \"PRX_TTY_\" in pred_value):\n",
    "        output_row.append(\"\\\"\"+\"item\"+\"\\\"\")\n",
    "    #Check if predicate is Identifier, then data type is an external-identifier\n",
    "    elif (\"PRX_ID_\" in pred_value):\n",
    "        output_row.append(\"\\\"\"+\"external-identifier\"+\"\\\"\")\n",
    "    #Else predicate is simply a string\n",
    "    elif (\"PRX_\" in pred_value):\n",
    "        output_row.append(\"\\\"\"+\"string\"+\"\\\"\")\n",
    "        \n",
    "    #Append the data-type triple to both PRXNode file and PRXNode DataType file\n",
    "    output_rows_prxnode.append(output_row)\n",
    "    output_rows_prxnode_datatype.append(output_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the results to PRXNode file\n",
    "filename_output= os.path.join(triples_output_path, 'prxnode_notinwiki.tsv')\n",
    "write_tsv(filename_output, output_rows_prxnode)\n",
    "\n",
    "#Write the results to PRXNode Edges file\n",
    "filename_output= os.path.join(triples_output_path, 'prxnode_notinwiki_edges.tsv')\n",
    "write_tsv(filename_output, output_rows_prxnode_edges)\n",
    "\n",
    "#Write the results to PRXNode Data-Type file\n",
    "filename_output= os.path.join(triples_output_path, 'prxnode_notinwiki_datatype.tsv')\n",
    "write_tsv(filename_output, output_rows_prxnode_datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triples Generated\n"
     ]
    }
   ],
   "source": [
    "print(\"Triples Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
